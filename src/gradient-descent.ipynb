{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    "    )\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define the neural network architecture\n",
    "\n",
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(3, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        \n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        \n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.out = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = self.res1(x) + x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.res2(x) + x\n",
    "        \n",
    "        x = F.max_pool2d(x, kernel_size=4)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "MINI_BATCH_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "    )\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    "    )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=MINI_BATCH_SIZE,\n",
    "    shuffle=True, # reshuffle data at every epoch\n",
    "    num_workers=2\n",
    "    )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    "    )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=MINI_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    "    )\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\",\n",
    "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "# Function definitions to train, test, and freeze the parameters of the neural network\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "''' Train the neural network using backpropagation with cross entropy as the loss function '''\n",
    "def train_nn(net: nn.Module, epochs: int, optimizer: torch.optim.Optimizer):\n",
    "  print(f'Initialising training ...')\n",
    "  print(f'- Epochs: {epochs}')\n",
    "  print(f'- Mini batch size: {MINI_BATCH_SIZE}')\n",
    "  print(f'- Optimiser: {optimizer}')\n",
    "  print(f'- Loss function: {F.cross_entropy.__name__}')\n",
    "\n",
    "  evaluation_loss_track = []\n",
    "  running_loss_track = []\n",
    "  accuracy_track = []\n",
    "\n",
    "  # loop over the dataset multiple times\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    # loop over the dataset and get mini-batch\n",
    "    for mini_batch in trainloader:\n",
    "      images = mini_batch[0].to(device)\n",
    "      labels = mini_batch[1].to(device)\n",
    "\n",
    "      optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "      preds = net(images) # forward mini-batch\n",
    "\n",
    "      loss = F.cross_entropy(preds, labels) # calculate loss\n",
    "      loss.backward() # calculate gradients with respect to each weight\n",
    "      optimizer.step() # update weights\n",
    "\n",
    "      running_loss += loss.item()\n",
    "\n",
    "      # track\n",
    "      evaluation_loss_track.append(loss.item())\n",
    "\n",
    "    accuracy = test_nn(net=net, verbose=False)\n",
    "    print(f'\\nEpoch {epoch} finished -- Running loss {running_loss} -- Accuracy {accuracy}')\n",
    "\n",
    "    # track\n",
    "    running_loss_track.append(running_loss)\n",
    "    accuracy_track.append(accuracy)\n",
    "\n",
    "  # plot\n",
    "  fig, ax1 = plt.subplots()\n",
    "\n",
    "  ax1.set_xlabel('Iterations over entire dataset (Epoch)')\n",
    "  \n",
    "  ax1.set_ylabel('Accuracy', color='b')\n",
    "  ax1.plot(np.array(accuracy_track), '--b', label='Accuracy', linewidth=0.5)\n",
    "\n",
    "  ax2 = ax1.twinx()\n",
    "  ax2.set_ylabel('Running loss per epoch', color='r')\n",
    "  ax2.plot(np.array(running_loss_track), '--r', label='Loss per epoch', linewidth=0.5)\n",
    "\n",
    "  fig.tight_layout()\n",
    "  fig.legend()\n",
    "  plt.show()\n",
    "\n",
    "''' Test the neural network '''\n",
    "def test_nn(net: nn.Module, verbose: bool):\n",
    "    # test the neural network\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct // total\n",
    "\n",
    "    if verbose:\n",
    "        print('Testing on 10,000 test images ...')\n",
    "        print(f'- Correct: {correct}')\n",
    "        print(f'- Total: {total}')\n",
    "        print(f'- Accuracy: {accuracy}')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "''' Freeze all the parameters except the last layer and randomize last layer '''\n",
    "def freeze_parameters(net: nn.Module):\n",
    "    # freeze all the parameters in the NN\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # unfreeze all the parameters from the last layer and randomise the weights\n",
    "    for param in net.out.parameters():\n",
    "        param.requires_grad = True\n",
    "        param.data = torch.rand(param.size(), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained neural network model and test it to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './nn-models/cifar10-nn-model'\n",
    "\n",
    "# load the pretrained NN model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.to(device=device)\n",
    "\n",
    "test_nn(net=net, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_parameters(net=net)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "train_nn(net=net, epochs=50, optimizer=optimizer)\n",
    "test_nn(net=net, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

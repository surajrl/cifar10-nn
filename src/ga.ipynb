{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nn_utils import Net, DEVICE, TRAINLOADER, train_nn, test_nn, freeze_parameters\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "PATH = './nn-models/cifar10-nn-model'\n",
    "\n",
    "# load the pretrained NN model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.to(device=DEVICE)\n",
    "\n",
    "test_nn(net=net, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from deap import base\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "freeze_parameters(net=net)\n",
    "\n",
    "# store all the training dataset in a single batch\n",
    "ALL_IMAGES = []\n",
    "ALL_LABELS = []\n",
    "for mini_batch in TRAINLOADER:\n",
    "    ALL_IMAGES.append(mini_batch[0])\n",
    "    ALL_LABELS.append(mini_batch[1])\n",
    "\n",
    "ALL_IMAGES = torch.cat(ALL_IMAGES)\n",
    "ALL_LABELS = torch.cat(ALL_LABELS)\n",
    "\n",
    "# count the number of dimensions of the last layer\n",
    "N_DIMENSION = 0\n",
    "for param in net.out.parameters():\n",
    "    N_DIMENSION += param.numel()\n",
    "\n",
    "LOW_BOUND = -0.1\n",
    "HIGH_BOUND = 0.3\n",
    "N_BITS = 8\n",
    "N_GENERATIONS = 100\n",
    "MU = 200\n",
    "CX_PB = 0.9\n",
    "UNIFORM_CX_PB = 0.5\n",
    "MUTATE_PB = 0.1\n",
    "MUTATE_FLIP_PB = 1.0 / (N_DIMENSION * N_BITS)\n",
    "ELITISM = 5\n",
    "\n",
    "def decode(individual):\n",
    "    real_numbers = []\n",
    "    for i in range(N_DIMENSION):\n",
    "        chromosome = individual[i*N_BITS:(i+1)*N_BITS]\n",
    "        bit_string = ''.join(map(str, chromosome))\n",
    "        num_as_int = int(bit_string, 2) # convert to int from base 2 list\n",
    "        num_in_range = LOW_BOUND + (HIGH_BOUND - LOW_BOUND) * num_as_int / 2**N_BITS\n",
    "        real_numbers.append(num_in_range)\n",
    "\n",
    "    return real_numbers\n",
    "\n",
    "def calculate_fitness(individual):\n",
    "    # put the parameters into the neural network\n",
    "    parameters = decode(individual=individual)\n",
    "    parameters = torch.as_tensor(parameters, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
    "    net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
    "\n",
    "    # go over the dataset once\n",
    "    with torch.no_grad():\n",
    "        # get a mini-batch from the training dataset\n",
    "        images = ALL_IMAGES[0:1000].to(device=DEVICE)\n",
    "        labels = ALL_LABELS[0:1000].to(device=DEVICE)\n",
    "\n",
    "        preds = net(images) # forward mini-batch\n",
    "        loss = F.cross_entropy(preds, labels) # calculate loss\n",
    "\n",
    "    return (1 / 0.1 + loss.item()),\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, N_BITS*N_DIMENSION)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", calculate_fitness)\n",
    "toolbox.register(\"crossover\", tools.cxUniform, indpb=UNIFORM_CX_PB)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=MUTATE_FLIP_PB)\n",
    "toolbox.register(\"select\", tools.selTournament, fit_attr='fitness')\n",
    "\n",
    "def ga():\n",
    "    # generate initial random population of individuals (parameters)\n",
    "    pop = toolbox.population(n=MU)\n",
    "\n",
    "    # evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # track the performance of each generation\n",
    "    best_individuals = [] \n",
    "    worst_individuals = [] \n",
    "\n",
    "    # begin the generational process\n",
    "    for gen in range(1, N_GENERATIONS):\n",
    "\n",
    "        # select the next generation individuals\n",
    "        offspring = tools.selBest(pop, ELITISM) + toolbox.select(pop, len(pop)-ELITISM, 2)\n",
    "        # clone the selected individuals\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "        # crossover make pairs of all (even, odd) in offspring\n",
    "        for ind1, ind2 in zip(offspring[4::2], offspring[5::2]):\n",
    "            if random.random() <= CX_PB:\n",
    "                toolbox.crossover(ind1, ind2)\n",
    "                del ind1.fitness.values\n",
    "                del ind2.fitness.values\n",
    "\n",
    "        # mutation\n",
    "        for mutant in offspring:\n",
    "            if random.random() <= MUTATE_PB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        # population is entirely replaced by the offspring\n",
    "        pop[:] = offspring\n",
    "\n",
    "        # track generation\n",
    "        print(f'==== Generation {gen} finished ====')\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "        best_individuals.append(min(fits))\n",
    "        worst_individuals.append(max(fits))\n",
    "\n",
    "    return pop, best_individuals, worst_individuals\n",
    "        \n",
    "pop, best_individuals, worst_individuals = ga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_individual = tools.selBest(pop, 1)[0]\n",
    "\n",
    "plt.plot(np.array(best_individuals), color='b', linestyle='dashed', marker='.', linewidth=0.5, label='Worst individual')\n",
    "plt.plot(np.array(worst_individuals), color='r', linestyle='dashed', marker='.', linewidth=0.5, label='Best individual')\n",
    "plt.ylabel('Fitness value (Loss function')\n",
    "plt.xlabel('Generation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put best parameters back into the neural network\n",
    "parameters = torch.as_tensor(best_individual, dtype=torch.float32, device=DEVICE)\n",
    "net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
    "net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
    "\n",
    "print(net.out.weight.shape)\n",
    "print(net.out.bias.shape)\n",
    "\n",
    "# test the neural network\n",
    "test_nn(net=net, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

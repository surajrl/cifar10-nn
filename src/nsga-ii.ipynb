{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network architecture, load the dataset and define train, test and freeze functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained neural network model and test it to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nn_utils import Net, DEVICE, TRAINLOADER, train_nn, test_nn, freeze_parameters\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "PATH = './nn-models/cifar10-nn-model'\n",
    "\n",
    "# load the pretrained NN model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.to(device=DEVICE)\n",
    "\n",
    "test_nn(net=net, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSGA-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from deap import base\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "freeze_parameters(net=net)\n",
    "\n",
    "LOW_BOUND = -0.1\n",
    "HIGH_BOUND = 0.3\n",
    "N_GENERATIONS = 200\n",
    "MU = 200\n",
    "CX_PB = 0.9\n",
    "MUTATE_PROB = 0.1\n",
    "\n",
    "# store all the training dataset in a single batch\n",
    "ALL_IMAGES = []\n",
    "ALL_LABELS = []\n",
    "for mini_batch in TRAINLOADER:\n",
    "    ALL_IMAGES.append(mini_batch[0])\n",
    "    ALL_LABELS.append(mini_batch[1])\n",
    "\n",
    "ALL_IMAGES = torch.cat(ALL_IMAGES)\n",
    "ALL_LABELS = torch.cat(ALL_LABELS)\n",
    "\n",
    "# count the number of dimensions of the last layer\n",
    "N_DIMENSION = 0\n",
    "for param in net.out.parameters():\n",
    "    N_DIMENSION += param.numel()\n",
    "\n",
    "# loss function\n",
    "def f1(individual):\n",
    "    # take the parameters from the individual and replace the last layer of the NN with them\n",
    "    parameters = torch.as_tensor(individual, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
    "    net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
    "   \n",
    "    # no need to calculate the gradient \n",
    "    with torch.no_grad():\n",
    "        # get a mini-batch from the training dataset\n",
    "        images = ALL_IMAGES[0:1000].to(device=DEVICE)\n",
    "        labels = ALL_LABELS[0:1000].to(device=DEVICE)\n",
    "\n",
    "        preds = net(images) # forward mini-batch\n",
    "        loss = F.cross_entropy(preds, labels) # calculate loss\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# Gaussian regulariser (sum of the square of the weights)\n",
    "def f2():\n",
    "    squared_weights = []\n",
    "    for param_name, param in net.named_parameters():\n",
    "        squared_weight = torch.square(param.data)\n",
    "        squared_weights.append(squared_weight)\n",
    "\n",
    "    sum = 0\n",
    "    for param in squared_weights:\n",
    "        sum += torch.sum(param)\n",
    "        \n",
    "    return sum.detach().cpu().numpy()\n",
    "\n",
    "def obj(individual):\n",
    "    return (f1(individual=individual), f2()) \n",
    "\n",
    "def uniform(low, up, size=None):\n",
    "    try:\n",
    "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "    except TypeError:\n",
    "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_float\", uniform, LOW_BOUND, HIGH_BOUND, N_DIMENSION)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", obj)\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=LOW_BOUND, up=HIGH_BOUND, eta=20.0)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=LOW_BOUND, up=HIGH_BOUND, eta=20.0, indpb=1.0/N_DIMENSION)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "def nsga_ii():\n",
    "    # generate initial random population of individuals (parameters)\n",
    "    pop = toolbox.population(n=MU)\n",
    "\n",
    "    # evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # this is just to assign the crowding distance to\n",
    "    # the individuals no actual selection is done\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    # begin the generational process\n",
    "    for gen in range(1, N_GENERATIONS):\n",
    "        # vary the population\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        \n",
    "        # selTournamentDCD means Tournament selection based on dominance (D) \n",
    "        # followed by crowding distance (CD). This selection requires the \n",
    "        # individuals to have a crowding_dist attribute\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "        # crossover make pairs of all (even, odd) in offspring\n",
    "        for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() <= CX_PB:\n",
    "                toolbox.mate(ind1, ind2)\n",
    "                del ind1.fitness.values\n",
    "                del ind2.fitness.values\n",
    "\n",
    "        # mutation\n",
    "        for mutant in offspring:\n",
    "            if random.random() <= MUTATE_PROB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # select the next generation population\n",
    "        pop = toolbox.select(pop + offspring, MU)\n",
    "        \n",
    "        print(f'generation {gen} finished')\n",
    "\n",
    "    return pop\n",
    "        \n",
    "pop = nsga_ii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.sort(key=lambda x: x.fitness.values)\n",
    "\n",
    "front = np.array([ind.fitness.values for ind in pop])\n",
    "plt.scatter(front[:,0], front[:,1], c=\"b\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlabel('Loss function')\n",
    "plt.ylabel('Sum of the squared weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put best parameters back into the neural network\n",
    "parameters = torch.as_tensor(pop[0], dtype=torch.float32, device=DEVICE)\n",
    "net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
    "net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
    "\n",
    "# test the neural network\n",
    "test_nn(net=net, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install deap"
      ],
      "metadata": {
        "id": "DeVTBlrPUGZb",
        "outputId": "6105a7cd-9ff5-4980-fa14-5119900b35d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.23.5)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-JCYKE-TxJi"
      },
      "source": [
        "Define the neural network architecture, load the dataset and define train, test and freeze functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wYdPvpLuTxJn",
        "outputId": "20276ebb-6ebc-44ae-d43f-9e7bbf3580ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 45267633.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        "    )\n",
        "\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define the neural network architecture\n",
        "\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv_block(3, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "        self.out = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        x = self.res1(x) + x\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        x = self.res2(x) + x\n",
        "\n",
        "        x = F.max_pool2d(x, kernel_size=4)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "MINI_BATCH_SIZE = 128\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "    )\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        "    )\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=MINI_BATCH_SIZE,\n",
        "    shuffle=True, # reshuffle data at every epoch\n",
        "    num_workers=2\n",
        "    )\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        "    )\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=MINI_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        "    )\n",
        "\n",
        "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\",\n",
        "           \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
        "\n",
        "# Function definitions to train, test, and freeze the parameters of the neural network\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "''' Train the neural network using backpropagation with cross entropy as the loss function '''\n",
        "def train_nn(net: nn.Module, epochs: int, optimizer: torch.optim.Optimizer):\n",
        "  print(f'Initialising training ...')\n",
        "  print(f'- Epochs: {epochs}')\n",
        "  print(f'- Mini batch size: {MINI_BATCH_SIZE}')\n",
        "  print(f'- Optimiser: {optimizer}')\n",
        "  print(f'- Loss function: {F.cross_entropy.__name__}')\n",
        "\n",
        "  evaluation_loss_track = []\n",
        "  running_loss_track = []\n",
        "  accuracy_track = []\n",
        "\n",
        "  # loop over the dataset multiple times\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "\n",
        "    # loop over the dataset and get mini-batch\n",
        "    for mini_batch in trainloader:\n",
        "      images = mini_batch[0].to(device)\n",
        "      labels = mini_batch[1].to(device)\n",
        "\n",
        "      optimizer.zero_grad() # zero the parameter gradients\n",
        "\n",
        "      preds = net(images) # forward mini-batch\n",
        "\n",
        "      loss = F.cross_entropy(preds, labels) # calculate loss\n",
        "      loss.backward() # calculate gradients with respect to each weight\n",
        "      optimizer.step() # update weights\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # track\n",
        "      evaluation_loss_track.append(loss.item())\n",
        "\n",
        "    accuracy = test_nn(net=net, verbose=False)\n",
        "    print(f'\\nEpoch {epoch} finished -- Running loss {running_loss} -- Accuracy {accuracy}')\n",
        "\n",
        "    # track\n",
        "    running_loss_track.append(running_loss)\n",
        "    accuracy_track.append(accuracy)\n",
        "\n",
        "  # plot\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  ax1.set_xlabel('Iterations over entire dataset (Epoch)')\n",
        "\n",
        "  ax1.set_ylabel('Accuracy', color='b')\n",
        "  ax1.plot(np.array(accuracy_track), '--b', label='Accuracy', linewidth=0.5)\n",
        "\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.set_ylabel('Running loss per epoch', color='r')\n",
        "  ax2.plot(np.array(running_loss_track), '--r', label='Loss per epoch', linewidth=0.5)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  fig.legend()\n",
        "  plt.show()\n",
        "\n",
        "''' Test the neural network '''\n",
        "def test_nn(net: nn.Module, verbose: bool):\n",
        "    # test the neural network\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images = data[0].to(device)\n",
        "            labels = data[1].to(device)\n",
        "\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct // total\n",
        "\n",
        "    if verbose:\n",
        "        print('Testing on 10,000 test images ...')\n",
        "        print(f'- Correct: {correct}')\n",
        "        print(f'- Total: {total}')\n",
        "        print(f'- Accuracy: {accuracy}')\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "''' Freeze all the parameters except the last layer and randomize last layer '''\n",
        "def freeze_parameters(net: nn.Module):\n",
        "    # freeze all the parameters in the NN\n",
        "    for param in net.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # unfreeze all the parameters from the last layer and randomise the weights\n",
        "    for param in net.out.parameters():\n",
        "        param.requires_grad = True\n",
        "        param.data = torch.rand(param.size(), device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCBgQfkbTxJw"
      },
      "source": [
        "Load the pre-trained neural network model and test it to check the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jIbh_Zf8TxJw",
        "outputId": "9541afdb-5246-4470-ebc7-9346dda62565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0370, device='cuda:0', grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "PATH = './nn-models/cifar10-nn-model'\n",
        "\n",
        "# load the pretrained NN model\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.to(device=device)\n",
        "\n",
        "# test_nn(net=net, verbose=True)\n",
        "\n",
        "torch.max(net.out.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0naLOfnTxJx"
      },
      "source": [
        "NSGA-II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tpA9dRqWTxJy",
        "outputId": "5ba98ba8-8874-43be-d3c3-51663efb36a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-e6a12b08be55>\u001b[0m in \u001b[0;36m<cell line: 145>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnsga_ii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-e6a12b08be55>\u001b[0m in \u001b[0;36mnsga_ii\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-e6a12b08be55>\u001b[0m in \u001b[0;36mobj\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-e6a12b08be55>\u001b[0m in \u001b[0;36mf1\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_LABELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward mini-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-03dbc66eec7e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.88 GiB. GPU 0 has a total capacty of 14.75 GiB of which 212.81 MiB is free. Process 5935 has 14.54 GiB memory in use. Of the allocated memory 7.49 GiB is allocated by PyTorch, and 5.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "import array\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from deap import base\n",
        "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "freeze_parameters(net=net)\n",
        "\n",
        "LOW_BOUND = -0.1\n",
        "HIGH_BOUND = 0.3\n",
        "N_GENERATIONS = 50\n",
        "MU = 100\n",
        "CXPB = 0.9\n",
        "MUTATE_PROB = 0.1\n",
        "\n",
        "# store all the training dataset in a single batch\n",
        "ALL_IMAGES = []\n",
        "ALL_LABELS = []\n",
        "for batch in trainloader:\n",
        "    ALL_IMAGES.append(batch[0])\n",
        "    ALL_LABELS.append(batch[1])\n",
        "\n",
        "ALL_IMAGES = torch.cat(ALL_IMAGES)\n",
        "ALL_LABELS = torch.cat(ALL_LABELS)\n",
        "\n",
        "# count the number of dimensions of the last layer\n",
        "N_DIMENSION = 0\n",
        "for param in net.out.parameters():\n",
        "    N_DIMENSION += param.numel()\n",
        "\n",
        "# loss function\n",
        "def f1(individual):\n",
        "    # take the parameters from the individual and replace the last layer of the NN with them\n",
        "    parameters = torch.as_tensor(individual, dtype=torch.float32, device=device)\n",
        "\n",
        "    net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
        "    net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
        "\n",
        "    # no need to calculate the gradient\n",
        "    with torch.no_grad():\n",
        "        # get a mini-batch from the training dataset\n",
        "        images = ALL_IMAGES[0:10000].to(device=device)\n",
        "        labels = ALL_LABELS[0:10000].to(device=device)\n",
        "\n",
        "        preds = net(images) # forward mini-batch\n",
        "        loss = F.cross_entropy(preds, labels) # calculate loss\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Gaussian regulariser (sum of the square of the weights)\n",
        "def f2():\n",
        "    squared_weights = []\n",
        "    for param_name, param in net.named_parameters():\n",
        "        squared_weight = torch.square(param.data)\n",
        "        squared_weights.append(squared_weight)\n",
        "\n",
        "    sum = 0\n",
        "    for param in squared_weights:\n",
        "        sum += torch.sum(param)\n",
        "\n",
        "    return sum.detach().cpu().numpy()\n",
        "\n",
        "def obj(individual):\n",
        "    return (f1(individual=individual), f2())\n",
        "\n",
        "def uniform(low, up, size=None):\n",
        "    try:\n",
        "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
        "    except TypeError:\n",
        "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
        "\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "toolbox.register(\"attr_float\", uniform, LOW_BOUND, HIGH_BOUND, N_DIMENSION)\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"evaluate\", obj)\n",
        "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=LOW_BOUND, up=HIGH_BOUND, eta=20.0)\n",
        "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=LOW_BOUND, up=HIGH_BOUND, eta=20.0, indpb=1.0/N_DIMENSION)\n",
        "toolbox.register(\"select\", tools.selNSGA2)\n",
        "\n",
        "def nsga_ii():\n",
        "    # generate initial random population of individuals (parameters)\n",
        "    pop = toolbox.population(n=MU)\n",
        "\n",
        "    gen_performance = []\n",
        "\n",
        "    # evaluate the individuals with an invalid fitness\n",
        "    invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    # this is just to assign the crowding distance to\n",
        "    # the individuals no actual selection is done\n",
        "    pop = toolbox.select(pop, len(pop))\n",
        "\n",
        "    # begin the generational process\n",
        "    for gen in range(1, N_GENERATIONS):\n",
        "        # vary the population\n",
        "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
        "\n",
        "        # selTournamentDCD means Tournament selection based on dominance (D)\n",
        "        # followed by crowding distance (CD). This selection requires the\n",
        "        # individuals to have a crowding_dist attribute\n",
        "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
        "\n",
        "        # crossover make pairs of all (even, odd) in offspring\n",
        "        for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() <= CXPB:\n",
        "                toolbox.mate(ind1, ind2)\n",
        "                del ind1.fitness.values\n",
        "                del ind2.fitness.values\n",
        "\n",
        "        # mutation\n",
        "        for mutant in offspring:\n",
        "            if random.random() <= MUTATE_PROB:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "        # evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        # select the next generation population\n",
        "        pop = toolbox.select(pop + offspring, MU)\n",
        "        print(f'generation {gen} finished')\n",
        "\n",
        "        # gather all the fitnesses in one list and print the stats\n",
        "        fits = [ind.fitness.values[0] for ind in pop]\n",
        "        gen_performance.append(max(fits))\n",
        "\n",
        "    return pop, gen_performance\n",
        "\n",
        "pop, gen_performance = nsga_ii()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C4eKy0YUTxJ0",
        "outputId": "d44d85b0-71a8-45d5-a66b-acece7291a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pop.sort(key=lambda x: x.fitness.values)\n",
        "\n",
        "front = np.array([ind.fitness.values for ind in pop])\n",
        "plt.scatter(front[:,0], front[:,1], c=\"b\")\n",
        "plt.axis(\"tight\")\n",
        "plt.xlabel('Loss function')\n",
        "plt.ylabel('Sum of the squared weights')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WlzzXMBdTxJ1",
        "outputId": "9399edfc-d05f-40f3-d79e-da42275474a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on 10,000 test images ...\n",
            "- Correct: 3112\n",
            "- Total: 10000\n",
            "- Accuracy: 31\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.2987, device='cuda:0', grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# put best parameters back into the neural network\n",
        "parameters = torch.as_tensor(pop[0], dtype=torch.float32, device=device)\n",
        "net.out.weight = torch.nn.Parameter(data=parameters[0:5120].reshape(10, 512))\n",
        "net.out.bias = torch.nn.Parameter(data=parameters[5120:5130])\n",
        "\n",
        "# test the neural network\n",
        "test_nn(net=net, verbose=True)\n",
        "\n",
        "torch.min(net.out.weight)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}